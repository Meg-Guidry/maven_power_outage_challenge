{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maven Power Outage Challenge - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this milestone I will be cleaning and analysing the Maven Analytics \"Power Outage Challenge\" dataset. \n",
    "\n",
    "Electricity outages are a growing concern as we enter an age of unprecedented energy demand and climate disasters. This dataset contains power outage data from across the USA going back to 2002. There are quite a few issues with data quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium \n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the sheet names in a list so that we can easily iterate through the excel sheets (tabs). \n",
    "# Each sheet contains power outage event data for a single year between 2002 and 2023\n",
    "\n",
    "sheet_names = [str(n) for n in range(2002, 2024, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary of pandas dataframes, one dataframe per excel sheet. \n",
    "# this will allow us to tailor our data cleaning to the individual sheet since the format of the sheet changes over the years.\n",
    "\n",
    "DF_dict = {}\n",
    "\n",
    "for sheet in sheet_names:\n",
    "    if sheet in [\"2002\", \"2008\"]:\n",
    "        header_value = 2\n",
    "    else:\n",
    "        header_value = 1\n",
    "    \n",
    "    DF_dict[\"{0}\".format(sheet)] = pd.read_excel('DOE_Electric_Disturbance_Events.xlsx', \n",
    "                                                 engine='openpyxl', \n",
    "                                                 header=header_value, \n",
    "                                                 sheet_name=sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will not use this right now, but the dictionary starting_shapes will help us to \n",
    "# understand the data better as we are cleaning\n",
    "\n",
    "starting_shapes = {}\n",
    "for sheet in sheet_names:\n",
    "    starting_shapes[sheet + \"_startshape\"] = DF_dict[str(sheet)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>NERC Region</th>\n",
       "      <th>Time</th>\n",
       "      <th>Area Affected</th>\n",
       "      <th>Type of Disturbance</th>\n",
       "      <th>Loss (megawatts)</th>\n",
       "      <th>Number of Customers Affected 1</th>\n",
       "      <th>Restoration</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Date/Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-04 00:00:00</td>\n",
       "      <td>WECC</td>\n",
       "      <td>4:00 a.m.</td>\n",
       "      <td>Northern California</td>\n",
       "      <td>Winter Storm</td>\n",
       "      <td>500</td>\n",
       "      <td>2606931</td>\n",
       "      <td>5:00 p.m. January 14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-04 00:00:00</td>\n",
       "      <td>WECC</td>\n",
       "      <td>7:47 a.m.</td>\n",
       "      <td>Sacramento County</td>\n",
       "      <td>Severe Storm</td>\n",
       "      <td>300</td>\n",
       "      <td>150000</td>\n",
       "      <td>4:30 p.m. January 04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-29 00:00:00</td>\n",
       "      <td>WECC</td>\n",
       "      <td>5:00 a.m.</td>\n",
       "      <td>San Francisco Bay Area, California</td>\n",
       "      <td>Exciter Faulted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>12:17 p.m. January 29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date NERC Region       Time  \\\n",
       "0                  NaN         NaN        NaN   \n",
       "1            January           NaN        NaN   \n",
       "2  2008-01-04 00:00:00        WECC  4:00 a.m.   \n",
       "3  2008-01-04 00:00:00        WECC  7:47 a.m.   \n",
       "4  2008-01-29 00:00:00        WECC  5:00 a.m.   \n",
       "\n",
       "                        Area Affected Type of Disturbance Loss (megawatts)  \\\n",
       "0                                 NaN                 NaN              NaN   \n",
       "1                                 NaN                 NaN              NaN   \n",
       "2                 Northern California        Winter Storm              500   \n",
       "3                   Sacramento County        Severe Storm              300   \n",
       "4  San Francisco Bay Area, California     Exciter Faulted              NaN   \n",
       "\n",
       "  Number of Customers Affected 1            Restoration  Unnamed: 8  \\\n",
       "0                            NaN              Date/Time         NaN   \n",
       "1                            NaN                    NaN         NaN   \n",
       "2                        2606931   5:00 p.m. January 14         NaN   \n",
       "3                         150000   4:30 p.m. January 04         NaN   \n",
       "4                              -  12:17 p.m. January 29         NaN   \n",
       "\n",
       "   Unnamed: 9  Unnamed: 10  Unnamed: 11  \n",
       "0         NaN          NaN          NaN  \n",
       "1         NaN          NaN          NaN  \n",
       "2         NaN          NaN          NaN  \n",
       "3         NaN          NaN          NaN  \n",
       "4         NaN          NaN          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets check out one of the dataframes to see if we get the data we expect:\n",
    "DF_dict[\"2008\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data above is what I expect, however it is very messy! Generally I will need to:\n",
    "- Make sure columns in each dataframe match (i.e. contain the same feature information)\n",
    "- Check data within the columns to ensure quality\n",
    "- Concatenate the source dataframes to create a single dataframe\n",
    "- Pre-process the data to address inconsistencies before EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>Date</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Time</td>\n",
       "      <td>Area</td>\n",
       "      <td>Type of Disturbance</td>\n",
       "      <td>Loss (megawatts)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>Restoration Time</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>Date</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Time</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>Type of Disturbance</td>\n",
       "      <td>Loss (megawatts)</td>\n",
       "      <td>Number of Customers Affected 1</td>\n",
       "      <td>Restoration</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>Date</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Time</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>Type of Disturbance</td>\n",
       "      <td>Loss (megawatts)</td>\n",
       "      <td>Number of Customers Affected 1</td>\n",
       "      <td>Restoration</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>Date</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Time</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>Type of Disturbance</td>\n",
       "      <td>Loss (megawatts)</td>\n",
       "      <td>Number of Customers Affected 1</td>\n",
       "      <td>Restoration</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>Date</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Time</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>Type of Disturbance</td>\n",
       "      <td>Loss (megawatts)</td>\n",
       "      <td>Number of Customers Affected 1</td>\n",
       "      <td>Restoration</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>Date</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Time</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>Type of Disturbance</td>\n",
       "      <td>Loss (megawatts)</td>\n",
       "      <td>Number of Customers Affected 1[1]</td>\n",
       "      <td>Restoration</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>Date</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Time</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>Type of Disturbance</td>\n",
       "      <td>Loss (megawatts)</td>\n",
       "      <td>Number of Customers Affected 1</td>\n",
       "      <td>Restoration</td>\n",
       "      <td>Unnamed: 8</td>\n",
       "      <td>Unnamed: 9</td>\n",
       "      <td>Unnamed: 10</td>\n",
       "      <td>Unnamed: 11</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>Date</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Time</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>Type of Disturbance</td>\n",
       "      <td>Loss (megawatts)</td>\n",
       "      <td>Number of Customers Affected 1</td>\n",
       "      <td>Restoration</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>Date</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Time</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>Type of Disturbance</td>\n",
       "      <td>Loss (megawatts)</td>\n",
       "      <td>Number of Customers Affected 1</td>\n",
       "      <td>Restoration</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>Unnamed: 9</td>\n",
       "      <td>Unnamed: 10</td>\n",
       "      <td>Unnamed: 11</td>\n",
       "      <td>Unnamed: 12</td>\n",
       "      <td>Unnamed: 13</td>\n",
       "      <td>Unnamed: 14</td>\n",
       "      <td>Unnamed: 15</td>\n",
       "      <td>Unnamed: 16</td>\n",
       "      <td>Unnamed: 17</td>\n",
       "      <td>Unnamed: 18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>Unnamed: 9</td>\n",
       "      <td>Unnamed: 10</td>\n",
       "      <td>Unnamed: 11</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>Unnamed: 9</td>\n",
       "      <td>Unnamed: 10</td>\n",
       "      <td>Unnamed: 11</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>Month</td>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Alert Criteria</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>Unnamed: 11</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>Month</td>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Alert Criteria</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>Unnamed: 11</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>Month</td>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Alert Criteria</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>Unnamed: 11</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>Month</td>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Alert Criteria</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>Month</td>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Alert Criteria</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>Month</td>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Alert Criteria</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>Month</td>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Alert Criteria</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Month</td>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Alert Criteria</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>Event Year</td>\n",
       "      <td>Event Month</td>\n",
       "      <td>Date Event Began</td>\n",
       "      <td>Time Event Began</td>\n",
       "      <td>Date of Restoration</td>\n",
       "      <td>Time of Restoration</td>\n",
       "      <td>Area Affected</td>\n",
       "      <td>NERC Region</td>\n",
       "      <td>Alert Criteria</td>\n",
       "      <td>Event Type</td>\n",
       "      <td>Demand Loss (MW)</td>\n",
       "      <td>Number of Customers Affected</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                 1                    2   \\\n",
       "2002              Date       NERC Region                 Time   \n",
       "2003              Date       NERC Region                 Time   \n",
       "2004              Date       NERC Region                 Time   \n",
       "2005              Date       NERC Region                 Time   \n",
       "2006              Date       NERC Region                 Time   \n",
       "2007              Date       NERC Region                 Time   \n",
       "2008              Date       NERC Region                 Time   \n",
       "2009              Date       NERC Region                 Time   \n",
       "2010              Date       NERC Region                 Time   \n",
       "2011  Date Event Began  Time Event Began  Date of Restoration   \n",
       "2012  Date Event Began  Time Event Began  Date of Restoration   \n",
       "2013  Date Event Began  Time Event Began  Date of Restoration   \n",
       "2014  Date Event Began  Time Event Began  Date of Restoration   \n",
       "2015             Month  Date Event Began     Time Event Began   \n",
       "2016             Month  Date Event Began     Time Event Began   \n",
       "2017             Month  Date Event Began     Time Event Began   \n",
       "2018             Month  Date Event Began     Time Event Began   \n",
       "2019             Month  Date Event Began     Time Event Began   \n",
       "2020             Month  Date Event Began     Time Event Began   \n",
       "2021             Month  Date Event Began     Time Event Began   \n",
       "2022             Month  Date Event Began     Time Event Began   \n",
       "2023        Event Year       Event Month     Date Event Began   \n",
       "\n",
       "                       3                    4                    5   \\\n",
       "2002                 Area  Type of Disturbance     Loss (megawatts)   \n",
       "2003        Area Affected  Type of Disturbance     Loss (megawatts)   \n",
       "2004        Area Affected  Type of Disturbance     Loss (megawatts)   \n",
       "2005        Area Affected  Type of Disturbance     Loss (megawatts)   \n",
       "2006        Area Affected  Type of Disturbance     Loss (megawatts)   \n",
       "2007        Area Affected  Type of Disturbance     Loss (megawatts)   \n",
       "2008        Area Affected  Type of Disturbance     Loss (megawatts)   \n",
       "2009        Area Affected  Type of Disturbance     Loss (megawatts)   \n",
       "2010        Area Affected  Type of Disturbance     Loss (megawatts)   \n",
       "2011  Time of Restoration        Area Affected          NERC Region   \n",
       "2012  Time of Restoration        Area Affected          NERC Region   \n",
       "2013  Time of Restoration        Area Affected          NERC Region   \n",
       "2014  Time of Restoration        Area Affected          NERC Region   \n",
       "2015  Date of Restoration  Time of Restoration        Area Affected   \n",
       "2016  Date of Restoration  Time of Restoration        Area Affected   \n",
       "2017  Date of Restoration  Time of Restoration        Area Affected   \n",
       "2018  Date of Restoration  Time of Restoration        Area Affected   \n",
       "2019  Date of Restoration  Time of Restoration        Area Affected   \n",
       "2020  Date of Restoration  Time of Restoration        Area Affected   \n",
       "2021  Date of Restoration  Time of Restoration        Area Affected   \n",
       "2022  Date of Restoration  Time of Restoration        Area Affected   \n",
       "2023     Time Event Began  Date of Restoration  Time of Restoration   \n",
       "\n",
       "                                     6                 7   \\\n",
       "2002       Number of Customers Affected  Restoration Time   \n",
       "2003     Number of Customers Affected 1       Restoration   \n",
       "2004     Number of Customers Affected 1       Restoration   \n",
       "2005     Number of Customers Affected 1       Restoration   \n",
       "2006     Number of Customers Affected 1       Restoration   \n",
       "2007  Number of Customers Affected 1[1]       Restoration   \n",
       "2008     Number of Customers Affected 1       Restoration   \n",
       "2009     Number of Customers Affected 1       Restoration   \n",
       "2010     Number of Customers Affected 1       Restoration   \n",
       "2011                         Event Type  Demand Loss (MW)   \n",
       "2012                         Event Type  Demand Loss (MW)   \n",
       "2013                         Event Type  Demand Loss (MW)   \n",
       "2014                         Event Type  Demand Loss (MW)   \n",
       "2015                        NERC Region    Alert Criteria   \n",
       "2016                        NERC Region    Alert Criteria   \n",
       "2017                        NERC Region    Alert Criteria   \n",
       "2018                        NERC Region    Alert Criteria   \n",
       "2019                        NERC Region    Alert Criteria   \n",
       "2020                        NERC Region    Alert Criteria   \n",
       "2021                        NERC Region    Alert Criteria   \n",
       "2022                        NERC Region    Alert Criteria   \n",
       "2023                      Area Affected       NERC Region   \n",
       "\n",
       "                                8                 9   \\\n",
       "2002                          None              None   \n",
       "2003                          None              None   \n",
       "2004                          None              None   \n",
       "2005                          None              None   \n",
       "2006                          None              None   \n",
       "2007                          None              None   \n",
       "2008                    Unnamed: 8        Unnamed: 9   \n",
       "2009                          None              None   \n",
       "2010                          None              None   \n",
       "2011  Number of Customers Affected        Unnamed: 9   \n",
       "2012  Number of Customers Affected        Unnamed: 9   \n",
       "2013  Number of Customers Affected              None   \n",
       "2014  Number of Customers Affected        Unnamed: 9   \n",
       "2015                    Event Type  Demand Loss (MW)   \n",
       "2016                    Event Type  Demand Loss (MW)   \n",
       "2017                    Event Type  Demand Loss (MW)   \n",
       "2018                    Event Type  Demand Loss (MW)   \n",
       "2019                    Event Type  Demand Loss (MW)   \n",
       "2020                    Event Type  Demand Loss (MW)   \n",
       "2021                    Event Type  Demand Loss (MW)   \n",
       "2022                    Event Type  Demand Loss (MW)   \n",
       "2023                Alert Criteria        Event Type   \n",
       "\n",
       "                                10                            11           12  \\\n",
       "2002                          None                          None         None   \n",
       "2003                          None                          None         None   \n",
       "2004                          None                          None         None   \n",
       "2005                          None                          None         None   \n",
       "2006                          None                          None         None   \n",
       "2007                          None                          None         None   \n",
       "2008                   Unnamed: 10                   Unnamed: 11         None   \n",
       "2009                          None                          None         None   \n",
       "2010                          None                          None         None   \n",
       "2011                   Unnamed: 10                   Unnamed: 11  Unnamed: 12   \n",
       "2012                   Unnamed: 10                   Unnamed: 11         None   \n",
       "2013                          None                          None         None   \n",
       "2014                   Unnamed: 10                   Unnamed: 11         None   \n",
       "2015  Number of Customers Affected                   Unnamed: 11         None   \n",
       "2016  Number of Customers Affected                   Unnamed: 11         None   \n",
       "2017  Number of Customers Affected                   Unnamed: 11         None   \n",
       "2018  Number of Customers Affected                          None         None   \n",
       "2019  Number of Customers Affected                          None         None   \n",
       "2020  Number of Customers Affected                          None         None   \n",
       "2021  Number of Customers Affected                          None         None   \n",
       "2022  Number of Customers Affected                          None         None   \n",
       "2023              Demand Loss (MW)  Number of Customers Affected         None   \n",
       "\n",
       "               13           14           15           16           17  \\\n",
       "2002         None         None         None         None         None   \n",
       "2003         None         None         None         None         None   \n",
       "2004         None         None         None         None         None   \n",
       "2005         None         None         None         None         None   \n",
       "2006         None         None         None         None         None   \n",
       "2007         None         None         None         None         None   \n",
       "2008         None         None         None         None         None   \n",
       "2009         None         None         None         None         None   \n",
       "2010         None         None         None         None         None   \n",
       "2011  Unnamed: 13  Unnamed: 14  Unnamed: 15  Unnamed: 16  Unnamed: 17   \n",
       "2012         None         None         None         None         None   \n",
       "2013         None         None         None         None         None   \n",
       "2014         None         None         None         None         None   \n",
       "2015         None         None         None         None         None   \n",
       "2016         None         None         None         None         None   \n",
       "2017         None         None         None         None         None   \n",
       "2018         None         None         None         None         None   \n",
       "2019         None         None         None         None         None   \n",
       "2020         None         None         None         None         None   \n",
       "2021         None         None         None         None         None   \n",
       "2022         None         None         None         None         None   \n",
       "2023         None         None         None         None         None   \n",
       "\n",
       "               18  \n",
       "2002         None  \n",
       "2003         None  \n",
       "2004         None  \n",
       "2005         None  \n",
       "2006         None  \n",
       "2007         None  \n",
       "2008         None  \n",
       "2009         None  \n",
       "2010         None  \n",
       "2011  Unnamed: 18  \n",
       "2012         None  \n",
       "2013         None  \n",
       "2014         None  \n",
       "2015         None  \n",
       "2016         None  \n",
       "2017         None  \n",
       "2018         None  \n",
       "2019         None  \n",
       "2020         None  \n",
       "2021         None  \n",
       "2022         None  \n",
       "2023         None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets explore how the column names vary between dataframes. Each row shows the column titles:\n",
    "\n",
    "column_title_dictionary = {\"{0}\".format(sheet):DF_dict[\"{0}\".format(sheet)].columns.tolist() for sheet in sheet_names}\n",
    "column_title_df = pd.DataFrame.from_dict(column_title_dictionary, orient='index') #use the orient argument to make the keys of the dictionary equivalent to the index values of the dataframe\n",
    "column_title_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The target column names\n",
    "\n",
    "From the dataframe above, we can see that the columns titles make a significant change two times between 2002 - 2023. \n",
    "\n",
    "I will approach the data cleaning process slightly differently for each of the three periods: 2002-2010, 2011-2014, 2015-2023\n",
    "\n",
    "Here are the column names that I will have in the cleaned and concatenated dataframe:\n",
    "1. \"datetime_event_began\", \n",
    "2. \"NERC_region\", \n",
    "3. \"area_affected\", \n",
    "4. \"event_type\", \n",
    "5. \"demand_loss_(MW)\", \n",
    "6. \"number_of_customers_affected\", \n",
    "7. \"datetime_of_restoration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_cleaning_column_titles = [\"datetime_event_began\", \n",
    "                               \"NERC_region\", \n",
    "                               \"area_affected\", \n",
    "                               \"event_type\", \n",
    "                               \"demand_loss_(MW)\", \n",
    "                               \"number_of_customers_affected\", \n",
    "                               \"datetime_of_restoration\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning dataframes from the years 2002 - 2010:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets create a function that takes a dataframe, iterates through the rows, and checkes that the \"Date\" column to a \n",
    "# datetime datatype. otherwise it drops the row because this indicates the row is an unexpected format and in this instance \n",
    "# most likely a human readable marker.\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def drop_non_datetime_values(dataframe_name, column_name):\n",
    "    for ind, row in dataframe_name.iterrows():\n",
    "        if type(dataframe_name[column_name][ind]) == datetime:\n",
    "            pass\n",
    "        else:\n",
    "            print(dataframe_name[column_name][ind]) # I have decided to print out the dropped data to make sure I am not dropping anyting unexpected. \n",
    "            dataframe_name.drop(axis=0, index=ind, inplace=True)\n",
    "    return dataframe_name\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January\n",
      "None\n",
      "February\n",
      "March\n",
      "April\n",
      "None\n",
      "July\n",
      "August\n",
      "October\n",
      "November\n",
      "None\n",
      "December\n",
      "None\n",
      "nan\n",
      "Note: North American Electric Reliability Council region acronyms are defined in the glossary.\n",
      "Source:  Form EIA-417, \"Electric Emergency Incident and Disturbance Report\"\n",
      "nan\n",
      "January\n",
      "February\n",
      "March\n",
      "None\n",
      "April\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "May\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "June\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "July\n",
      "nan\n",
      "nan\n",
      "Table B.2.\n",
      "(Continued)\n",
      "Date\n",
      "August\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "September\n",
      "nan\n",
      "nan\n",
      "Table B.2.\n",
      "(Continued)\n",
      "Date\n",
      "nan\n",
      "October\n",
      "November\n",
      "December\n",
      "1 = Estimated Values.\n",
      "* Information as provided by the respondent.  The occurrence is, however, associated with the \n",
      "massive blackout of August 14, 2003.  For further information, refer to the Interim Report: \n",
      "Causes of the August 14 Blackout in the United States and Canada, November 2003 at  \n",
      "http://www.energy.gov/engine/content.do.  \n",
      "Note: North American Electric Reliability Council region acronyms are defined in the glossary.\n",
      "Source:  Form EIA-417, \"Electric Emergency Incident and Disturbance Report.\"\n",
      "nan\n",
      "January\n",
      "February\n",
      "March\n",
      "April\n",
      "May\n",
      "None\n",
      "nan\n",
      "nan\n",
      "Table B.2.\n",
      "(Continued)\n",
      "Date\n",
      "nan\n",
      "June\n",
      "July\n",
      "August\n",
      "nan\n",
      "Table B.2.\n",
      "(Continued)\n",
      "Date\n",
      "nan\n",
      "nan\n",
      "September\n",
      "nan\n",
      "Table B.2.\n",
      "(Continued)\n",
      "Date\n",
      "nan\n",
      "October\n",
      "November\n",
      "December\n",
      "nan\n",
      "nan\n",
      "Table B.2.\n",
      "(Continued)\n",
      "Date\n",
      "nan\n",
      "nan\n",
      "1 = Estimated Values.\n",
      "Note: North American Electric Reliability Council region acronyms are defined in the glossary.\n",
      "Source:  Form EIA-417, \"Electric Emergency Incident and Disturbance Report.\"\n",
      "nan\n",
      "January\n",
      " 1/19/05\n",
      "February \n",
      "March\n",
      "April\n",
      "May\n",
      "June\n",
      "nan\n",
      "nan\n",
      "Table B.2.\n",
      "(Continued)\n",
      "Date\n",
      "nan\n",
      "July\n",
      "7/01//05\n",
      "nan\n",
      "August\n",
      "nan\n",
      "Table B.2.\n",
      "(Continued)\n",
      "Date\n",
      "nan\n",
      "September\n",
      "nan\n",
      "nan\n",
      "Table B.2.\n",
      "(Continued)\n",
      "Date\n",
      "nan\n",
      "nan\n",
      "October\n",
      "November\n",
      "nan\n",
      "nan\n",
      "Table B.2.\n",
      "(Continued)\n",
      "Date\n",
      "nan\n",
      "nan\n",
      "December\n",
      "1 = Estimated Values.\n",
      "Note: North American Electric Reliability Council region acronyms are defined in the glossary.\n",
      "Source:  Form OE-417, \"Electric Emergency Incident and Disturbance Report.\"\n",
      "nan\n",
      "January\n",
      "February\n",
      "March\n",
      "April\n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2006+A55\n",
      "Date\n",
      "May\n",
      "June\n",
      "July\n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2006\n",
      "Date\n",
      "August\n",
      "September\n",
      "October\n",
      "November\n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2006\n",
      "Date\n",
      "December\n",
      "[1] Estimated values.\n",
      "  Note: Estimates for 2004 and 2005 are preliminary.  \n",
      "  Source: Form OE-417, \"Electric Emergency Incident and Disturbance Report.\"\n",
      "January  \n",
      "February \n",
      "March    \n",
      "April    \n",
      "May      \n",
      "June     \n",
      "Table B.1.Major Disturbances and Unusual Occurrences, Year-to-Date through December 2007\n",
      "Date\n",
      "July     \n",
      "August   \n",
      "September\n",
      "Table B.1.Major Disturbances and Unusual Occurrences, Year-to-Date through December 2007\n",
      "Date\n",
      "October  \n",
      "November \n",
      "December \n",
      "[1] Estimated values.\n",
      "  Note: Estimates for 2007 are preliminary.\n",
      "  Source: Form OE-417, \"Electric Emergency Incident and Disturbance Report.\"\n",
      "nan\n",
      "January  \n",
      "February \n",
      "nan\n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2008\n",
      "Date\n",
      "nan\n",
      "March    \n",
      "April    \n",
      "May      \n",
      "June     \n",
      "nan\n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2008\n",
      "Date\n",
      "nan\n",
      "nan\n",
      "July     \n",
      "nan\n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2008\n",
      "Date\n",
      "nan\n",
      "nan\n",
      "August   \n",
      "September\n",
      "nan\n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2008\n",
      "Date\n",
      "nan\n",
      "nan\n",
      "October  \n",
      "November \n",
      "December \n",
      "nan\n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2008\n",
      "Date\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "[1] Estimated values.\n",
      "  Note: Estimates for 2008 are preliminary.\n",
      "  Source: Form OE-417, \"Electric Emergency Incident and Disturbance Report.\"\n",
      "nan\n",
      "January  \n",
      "February \n",
      "March    \n",
      "nan\n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2009\n",
      "Date\n",
      "nan\n",
      "nan\n",
      "April    \n",
      "May      \n",
      "June     \n",
      "July     \n",
      "nan\n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2009\n",
      "Date\n",
      "nan\n",
      "nan\n",
      "August   \n",
      "October  \n",
      "November \n",
      "December \n",
      "nan\n",
      "nan\n",
      "[1] Estimated values.\n",
      "  Note: Estimates for 2009 are preliminary.\n",
      "  Source: Form OE-417, \"Electric Emergency Incident and Disturbance Report.\"\n",
      "January  \n",
      "February \n",
      "March    \n",
      "April    \n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2010\n",
      "Date\n",
      "May      \n",
      "June     \n",
      "July     \n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2010\n",
      "Date\n",
      "August   \n",
      "September\n",
      "October  \n",
      "Table B.2.  Major Disturbances and Unusual Occurrences, Year-to-Date through December 2010\n",
      "Date\n",
      "November \n",
      "December \n",
      "[1] Estimated values.\n",
      "  Note: Estimates for 2010 are preliminary.\n",
      "  Source: Form OE-417, \"Electric Emergency Incident and Disturbance Report.\"\n"
     ]
    }
   ],
   "source": [
    "# Removing rows from the dataframe that are redundant or that repeat the column names.\n",
    "for sheet in list(range(2002,2011,1)):\n",
    "    drop_non_datetime_values(DF_dict[\"{0}\".format(sheet)], \"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets focus our attention on the \"Time\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have discovered some \"Time\" value that can not be changed to a time datatype due to how \n",
    "# they have been entered into the database. I will adjust these one-by-one to preserve as much information as possible:\n",
    "\n",
    "DF_dict[\"2002\"].loc[3, \"Time\"] = \"20:00:00\"  # Original value = \"Evening\"\n",
    "DF_dict[\"2003\"].loc[56, \"Time\"] = \"15:00:00\" # Original value = \"Approximately 3:00 p.m.\"\n",
    "DF_dict[\"2003\"].loc[78, \"Time\"] = \"12:00:00\" # Original value = \"12:00 noon\"\n",
    "DF_dict[\"2004\"].loc[3, \"Time\"] = \"00:00:00\"  # Original value = \"Midnight\"\n",
    "DF_dict[\"2004\"].loc[81, \"Time\"] = \"09:52:00\" # Original value = \"9: 52 a.m.\"\n",
    "DF_dict[\"2005\"].loc[13, \"Time\"] = \"17:28:00\" # Original value = \"5:78 p.m.\"\n",
    "DF_dict[\"2005\"].loc[21, \"Time\"] = \"00:00:00\" # Original value = \"Midnight\"\n",
    "DF_dict[\"2006\"].loc[12, \"Time\"] = \"00:00:00\" # Original value = \"Ongoing\"\n",
    "\n",
    "# This is the code I used to find the index value of the problematic time data:\n",
    "# DataFrame_dict[\"sheet2006\"][DataFrame_dict[\"sheet2006\"][\"Time\"] == \"Ongoing\"].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that the date and time columns are in a format that can be recognised by pd.to_datetime, \n",
    "# lets concatenate these two columns\n",
    "\n",
    "for sheet in list(range(2002,2011,1)):\n",
    "    DF_dict[\"{0}\".format(sheet)]['Date'] = pd.to_datetime(DF_dict[\"{0}\".format(sheet)]['Date'].astype(str) + ' ' + DF_dict[\"{0}\".format(sheet)]['Time'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that the time data is included in the first column of our dataframe we can drop the \"Time\" column \n",
    "# from the dataframes containing data for years 2002 - 2010\n",
    "\n",
    "for sheet in list(range(2002,2011,1)):\n",
    "    DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].drop(\"Time\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>NERC Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>Type of Disturbance</th>\n",
       "      <th>Loss (megawatts)</th>\n",
       "      <th>Number of Customers Affected</th>\n",
       "      <th>Restoration Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-01-30 06:00:00</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>500</td>\n",
       "      <td>1881134</td>\n",
       "      <td>2002-02-07 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-01-29 20:00:00</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Metropolitan Kansas City Area</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>500-600</td>\n",
       "      <td>270000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-01-30 16:00:00</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>210</td>\n",
       "      <td>95000</td>\n",
       "      <td>2002-02-10 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002-02-27 10:48:00</td>\n",
       "      <td>WSCC</td>\n",
       "      <td>California</td>\n",
       "      <td>Interruption of Firm Load</td>\n",
       "      <td>300</td>\n",
       "      <td>255000</td>\n",
       "      <td>2002-02-27 11:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2002-03-09 00:00:00</td>\n",
       "      <td>ECAR</td>\n",
       "      <td>Lower Peninsula of Michigan</td>\n",
       "      <td>Severe Weather</td>\n",
       "      <td>190</td>\n",
       "      <td>190000</td>\n",
       "      <td>2002-03-11 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date NERC Region                           Area  \\\n",
       "1 2002-01-30 06:00:00         SPP                       Oklahoma   \n",
       "3 2002-01-29 20:00:00         SPP  Metropolitan Kansas City Area   \n",
       "4 2002-01-30 16:00:00         SPP                       Missouri   \n",
       "6 2002-02-27 10:48:00        WSCC                     California   \n",
       "8 2002-03-09 00:00:00        ECAR    Lower Peninsula of Michigan   \n",
       "\n",
       "         Type of Disturbance Loss (megawatts) Number of Customers Affected  \\\n",
       "1                  Ice Storm              500                      1881134   \n",
       "3                  Ice Storm          500-600                       270000   \n",
       "4                  Ice Storm              210                        95000   \n",
       "6  Interruption of Firm Load              300                       255000   \n",
       "8             Severe Weather              190                       190000   \n",
       "\n",
       "      Restoration Time  \n",
       "1  2002-02-07 12:00:00  \n",
       "3                  NaN  \n",
       "4  2002-02-10 21:00:00  \n",
       "6  2002-02-27 11:35:00  \n",
       "8  2002-03-11 12:00:00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check that the Date column now containes datetimes that include both date and time:\n",
    "DF_dict[\"2002\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23 entries, 1 to 35\n",
      "Data columns (total 7 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   Date                          23 non-null     datetime64[ns]\n",
      " 1   NERC Region                   23 non-null     object        \n",
      " 2   Area                          23 non-null     object        \n",
      " 3   Type of Disturbance           23 non-null     object        \n",
      " 4   Loss (megawatts)              19 non-null     object        \n",
      " 5   Number of Customers Affected  23 non-null     object        \n",
      " 6   Restoration Time              22 non-null     object        \n",
      "dtypes: datetime64[ns](1), object(6)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "DF_dict[\"2002\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that dataframes for 2002 - 2010 are fairly clean let us standardise the column names so we can concatenate the dataframes:\n",
    "\n",
    "for sheet in list(range(2002,2011,1)):\n",
    "    old_col = DF_dict[\"{0}\".format(sheet)].columns.tolist()\n",
    "    for n in range(len(post_cleaning_column_titles)):\n",
    "        DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].rename(columns={old_col[n]: post_cleaning_column_titles[n]})\n",
    "        \n",
    "    if len(old_col) > 7: #Drop all additional columns. some sheets had extra columns filled with NaNs\n",
    "        for x in range(7,len(old_col),1):\n",
    "            DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].drop(old_col[x], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_event_began</th>\n",
       "      <th>NERC_region</th>\n",
       "      <th>area_affected</th>\n",
       "      <th>event_type</th>\n",
       "      <th>demand_loss_(MW)</th>\n",
       "      <th>number_of_customers_affected</th>\n",
       "      <th>datetime_of_restoration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-01-30 06:00:00</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>500</td>\n",
       "      <td>1881134</td>\n",
       "      <td>2002-02-07 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-01-29 20:00:00</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Metropolitan Kansas City Area</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>500-600</td>\n",
       "      <td>270000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-01-30 16:00:00</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>210</td>\n",
       "      <td>95000</td>\n",
       "      <td>2002-02-10 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002-02-27 10:48:00</td>\n",
       "      <td>WSCC</td>\n",
       "      <td>California</td>\n",
       "      <td>Interruption of Firm Load</td>\n",
       "      <td>300</td>\n",
       "      <td>255000</td>\n",
       "      <td>2002-02-27 11:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2002-03-09 00:00:00</td>\n",
       "      <td>ECAR</td>\n",
       "      <td>Lower Peninsula of Michigan</td>\n",
       "      <td>Severe Weather</td>\n",
       "      <td>190</td>\n",
       "      <td>190000</td>\n",
       "      <td>2002-03-11 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  datetime_event_began NERC_region                  area_affected  \\\n",
       "1  2002-01-30 06:00:00         SPP                       Oklahoma   \n",
       "3  2002-01-29 20:00:00         SPP  Metropolitan Kansas City Area   \n",
       "4  2002-01-30 16:00:00         SPP                       Missouri   \n",
       "6  2002-02-27 10:48:00        WSCC                     California   \n",
       "8  2002-03-09 00:00:00        ECAR    Lower Peninsula of Michigan   \n",
       "\n",
       "                  event_type demand_loss_(MW) number_of_customers_affected  \\\n",
       "1                  Ice Storm              500                      1881134   \n",
       "3                  Ice Storm          500-600                       270000   \n",
       "4                  Ice Storm              210                        95000   \n",
       "6  Interruption of Firm Load              300                       255000   \n",
       "8             Severe Weather              190                       190000   \n",
       "\n",
       "  datetime_of_restoration  \n",
       "1     2002-02-07 12:00:00  \n",
       "3                     NaN  \n",
       "4     2002-02-10 21:00:00  \n",
       "6     2002-02-27 11:35:00  \n",
       "8     2002-03-11 12:00:00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_dict[\"2002\"].head() #Note, there is still some cleaning to do but we have the dataframe in the general format we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will transform the \"datetime_of_restoration\" column into a datetime column which involves \n",
    "standardising the format of the date strings before using strptime with a .apply function to change \n",
    "the data strings to a recognisable datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we move on to clean the next section of sheets lets \n",
    "# create a function that standardises the format of the data in the column titled \"datetime_of_restoration\". \n",
    "# The data in this column has lots of data entry inconsistencies. I will use nested try/ except statements to increase the \n",
    "# chance of identifying and parsing the straing into a datetime in an semi-automated way. \n",
    "# The date that is still not recognised will be manually changed\n",
    "\n",
    "def standardise_date_format(date_val):\n",
    "    if type(date_val) != datetime:\n",
    "        try:\n",
    "            date_val = datetime.strptime(str(date_val), \"%Y-%m-%d %H:%M:%S\")\n",
    "        except:\n",
    "            try:\n",
    "                date_val = datetime.strptime(str(date_val), \"%m/%d/%y, %I:%M %p\")\n",
    "            except:\n",
    "                try:\n",
    "                    date_val = date_val.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    date_val = datetime.strptime(str(date_val), \"%Y-%m-%d %H:%M:%S\")\n",
    "                except:\n",
    "                    try:\n",
    "                        date_val = datetime.strptime(str(date_val), \"%I:%M  %p%B %d%Y\")\n",
    "                    except:\n",
    "                        try:\n",
    "                            date_val = datetime.strptime(str(date_val), \"%I:%M %p%B %d%Y\")\n",
    "                        except:\n",
    "                            try:\n",
    "                                date_val = datetime.strptime(str(date_val), \"%I:%M %p %B %d%Y\")\n",
    "                            except:\n",
    "                                try:\n",
    "                                    date_val = datetime.strptime(str(date_val), \"%I:%M%p%B %d%Y\")\n",
    "                                except ValueError:\n",
    "                                        date_val = None\n",
    "                    \n",
    "            \n",
    "        \n",
    "    return date_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding year to some of the raw data columns so that we can more easily convert to a datetime in a few steps:\n",
    "DF_dict[\"2006\"][\"datetime_of_restoration\"] = DF_dict[\"2006\"][\"datetime_of_restoration\"] + \"2006\"\n",
    "DF_dict[\"2007\"][\"datetime_of_restoration\"] = DF_dict[\"2007\"][\"datetime_of_restoration\"] + \"2007\"\n",
    "DF_dict[\"2008\"][\"datetime_of_restoration\"] = DF_dict[\"2008\"][\"datetime_of_restoration\"] + \"2008\"\n",
    "DF_dict[\"2009\"][\"datetime_of_restoration\"] = DF_dict[\"2009\"][\"datetime_of_restoration\"] + \"2009\"\n",
    "DF_dict[\"2010\"][\"datetime_of_restoration\"] = DF_dict[\"2010\"][\"datetime_of_restoration\"] + \"2010\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Individual values in the 2002 \"datetime_of_restoration\" column that I want to reformat manually:\n",
    "DF_dict[\"2002\"][\"datetime_of_restoration\"][24] = datetime(2002, 11, 10, 12, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Individual values in the 2003 \"datetime_of_restoration\" column that I want to reformat manually:\n",
    "\n",
    "DF_dict[\"2003\"][\"datetime_of_restoration\"][16] = datetime(2003, 4, 29, 12, 0, 0)\n",
    "DF_dict[\"2003\"][\"datetime_of_restoration\"][20] = datetime(2003, 4, 29, 12, 0, 0)\n",
    "DF_dict[\"2003\"][\"datetime_of_restoration\"][56] = datetime(2003, 8, 17, 17, 0, 0)\n",
    "DF_dict[\"2003\"][\"datetime_of_restoration\"][69] = datetime(2003, 8, 15, 6, 0, 0)\n",
    "DF_dict[\"2003\"][\"datetime_of_restoration\"][72] = datetime(2003, 8, 29, 12, 0, 0)\n",
    "DF_dict[\"2003\"][\"datetime_of_restoration\"][77] = datetime(2003, 9, 18, 0, 0, 0)\n",
    "DF_dict[\"2003\"][\"datetime_of_restoration\"][79] = datetime(2003, 9, 24, 0, 0, 0)\n",
    "DF_dict[\"2003\"][\"datetime_of_restoration\"][90] = datetime(2003, 11, 18, 10, 54, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Individual values in the 2004 \"datetime_of_restoration\" column that I want to reformat manually:\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][5] = datetime(2004, 1, 17, 12, 0, 0)\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][12] = datetime(2004, 2, 16, 12, 0, 0)\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][18] = datetime(2004, 3, 9, 8, 0, 0)\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][22] = datetime(2004, 4, 11, 16, 0, 0)\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][57] = datetime(2004, 7, 17, 8, 0, 0)\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][61] = datetime(2004, 7, 25, 21, 0, 0)\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][74] = datetime(2004, 8, 23, 0, 0, 0)\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][76] = datetime(2004, 8, 13, 0, 0, 0)\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][88] = datetime(2004, 9, 12, 0, 0, 0)\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][91] = datetime(2004, 9, 23, 12, 0, 0)\n",
    "DF_dict[\"2004\"][\"datetime_of_restoration\"][115] = datetime(2004, 11, 12, 13, 7, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Individual values in the 2005 \"datetime_of_restoration\" column that I want to reformat manually:\n",
    "DF_dict[\"2005\"][\"datetime_of_restoration\"][7] = datetime(2005, 1, 23, 11, 24, 0)\n",
    "DF_dict[\"2005\"][\"datetime_of_restoration\"][10] = datetime(2005, 1, 31, 10, 0, 0)\n",
    "DF_dict[\"2005\"][\"datetime_of_restoration\"][14] = datetime(2005, 2, 15, 13, 30, 0)\n",
    "DF_dict[\"2005\"][\"datetime_of_restoration\"][42] = datetime(2005, 6, 20, 17, 15, 0)\n",
    "DF_dict[\"2005\"][\"datetime_of_restoration\"][44] = None\n",
    "DF_dict[\"2005\"][\"datetime_of_restoration\"][52] = datetime(2005, 7, 11, 17, 33, 0)\n",
    "DF_dict[\"2005\"][\"datetime_of_restoration\"][77] = datetime(2005, 9, 8, 0, 1, 0)\n",
    "DF_dict[\"2005\"][\"datetime_of_restoration\"][98] = datetime(2005, 10, 2, 17, 0, 0)\n",
    "DF_dict[\"2005\"][\"datetime_of_restoration\"][102] = datetime(2005, 10, 18, 15, 37, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Individual values in the 2008 \"datetime_of_restoration\" column that I want to reformat manually:\n",
    "DF_dict[\"2008\"][\"datetime_of_restoration\"][57] = datetime(2008, 6, 4, 15, 46, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sheet in list(range(2003, 2011, 1)): #NOTE - we do not include 2002 because 2002 does not use am/pm markers\n",
    "    DF_dict[\"{0}\".format(sheet)][\"datetime_of_restoration\"] = DF_dict[\"{0}\".format(sheet)][\"datetime_of_restoration\"].str.replace(\"a.m.\", \"AM\")\n",
    "    DF_dict[\"{0}\".format(sheet)][\"datetime_of_restoration\"] = DF_dict[\"{0}\".format(sheet)][\"datetime_of_restoration\"].str.replace(\"p.m.\", \"PM\")\n",
    "    DF_dict[\"{0}\".format(sheet)][\"datetime_of_restoration\"] = DF_dict[\"{0}\".format(sheet)][\"datetime_of_restoration\"].str.replace(\"PM \", \"PM\")\n",
    "    DF_dict[\"{0}\".format(sheet)][\"datetime_of_restoration\"] = DF_dict[\"{0}\".format(sheet)][\"datetime_of_restoration\"].str.replace(\"AM \", \"AM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sheet in list(range(2002, 2011, 1)):\n",
    "    DF_dict[\"{0}\".format(sheet)][\"datetime_of_restoration_cleaned\"] = DF_dict[\"{0}\".format(sheet)][\"datetime_of_restoration\"].apply(standardise_date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23 entries, 1 to 35\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   datetime_event_began             23 non-null     datetime64[ns]\n",
      " 1   NERC_region                      23 non-null     object        \n",
      " 2   area_affected                    23 non-null     object        \n",
      " 3   event_type                       23 non-null     object        \n",
      " 4   demand_loss_(MW)                 19 non-null     object        \n",
      " 5   number_of_customers_affected     23 non-null     object        \n",
      " 6   datetime_of_restoration          22 non-null     object        \n",
      " 7   datetime_of_restoration_cleaned  21 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(6)\n",
      "memory usage: 1.6+ KB\n",
      "These are the columns for sheet 2002 None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 61 entries, 2 to 109\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   datetime_event_began             61 non-null     datetime64[ns]\n",
      " 1   NERC_region                      61 non-null     object        \n",
      " 2   area_affected                    61 non-null     object        \n",
      " 3   event_type                       61 non-null     object        \n",
      " 4   demand_loss_(MW)                 55 non-null     object        \n",
      " 5   number_of_customers_affected     57 non-null     object        \n",
      " 6   datetime_of_restoration          53 non-null     object        \n",
      " 7   datetime_of_restoration_cleaned  52 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(6)\n",
      "memory usage: 4.9+ KB\n",
      "These are the columns for sheet 2003 None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 93 entries, 2 to 129\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   datetime_event_began             93 non-null     datetime64[ns]\n",
      " 1   NERC_region                      93 non-null     object        \n",
      " 2   area_affected                    93 non-null     object        \n",
      " 3   event_type                       93 non-null     object        \n",
      " 4   demand_loss_(MW)                 93 non-null     object        \n",
      " 5   number_of_customers_affected     93 non-null     object        \n",
      " 6   datetime_of_restoration          82 non-null     object        \n",
      " 7   datetime_of_restoration_cleaned  82 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(6)\n",
      "memory usage: 6.4+ KB\n",
      "These are the columns for sheet 2004 None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 83 entries, 2 to 123\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   datetime_event_began             83 non-null     datetime64[ns]\n",
      " 1   NERC_region                      83 non-null     object        \n",
      " 2   area_affected                    83 non-null     object        \n",
      " 3   event_type                       83 non-null     object        \n",
      " 4   demand_loss_(MW)                 73 non-null     object        \n",
      " 5   number_of_customers_affected     77 non-null     object        \n",
      " 6   datetime_of_restoration          74 non-null     object        \n",
      " 7   datetime_of_restoration_cleaned  74 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(6)\n",
      "memory usage: 5.9+ KB\n",
      "These are the columns for sheet 2005 None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 91 entries, 1 to 108\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   datetime_event_began             91 non-null     datetime64[ns]\n",
      " 1   NERC_region                      91 non-null     object        \n",
      " 2   area_affected                    91 non-null     object        \n",
      " 3   event_type                       91 non-null     object        \n",
      " 4   demand_loss_(MW)                 72 non-null     object        \n",
      " 5   number_of_customers_affected     84 non-null     object        \n",
      " 6   datetime_of_restoration          91 non-null     object        \n",
      " 7   datetime_of_restoration_cleaned  90 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(6)\n",
      "memory usage: 6.3+ KB\n",
      "These are the columns for sheet 2006 None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78 entries, 1 to 93\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   datetime_event_began             78 non-null     datetime64[ns]\n",
      " 1   NERC_region                      78 non-null     object        \n",
      " 2   area_affected                    78 non-null     object        \n",
      " 3   event_type                       78 non-null     object        \n",
      " 4   demand_loss_(MW)                 60 non-null     object        \n",
      " 5   number_of_customers_affected     66 non-null     object        \n",
      " 6   datetime_of_restoration          78 non-null     object        \n",
      " 7   datetime_of_restoration_cleaned  76 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(6)\n",
      "memory usage: 3.7+ KB\n",
      "These are the columns for sheet 2007 None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 149 entries, 2 to 185\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   datetime_event_began             149 non-null    datetime64[ns]\n",
      " 1   NERC_region                      149 non-null    object        \n",
      " 2   area_affected                    149 non-null    object        \n",
      " 3   event_type                       149 non-null    object        \n",
      " 4   demand_loss_(MW)                 96 non-null     object        \n",
      " 5   number_of_customers_affected     146 non-null    object        \n",
      " 6   datetime_of_restoration          148 non-null    object        \n",
      " 7   datetime_of_restoration_cleaned  147 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(6)\n",
      "memory usage: 11.0+ KB\n",
      "These are the columns for sheet 2008 None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 97 entries, 2 to 118\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   datetime_event_began             97 non-null     datetime64[ns]\n",
      " 1   NERC_region                      97 non-null     object        \n",
      " 2   area_affected                    97 non-null     object        \n",
      " 3   event_type                       97 non-null     object        \n",
      " 4   demand_loss_(MW)                 57 non-null     object        \n",
      " 5   number_of_customers_affected     80 non-null     object        \n",
      " 6   datetime_of_restoration          97 non-null     object        \n",
      " 7   datetime_of_restoration_cleaned  96 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(6)\n",
      "memory usage: 4.5+ KB\n",
      "These are the columns for sheet 2009 None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 123 entries, 1 to 140\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   datetime_event_began             123 non-null    datetime64[ns]\n",
      " 1   NERC_region                      123 non-null    object        \n",
      " 2   area_affected                    123 non-null    object        \n",
      " 3   event_type                       123 non-null    object        \n",
      " 4   demand_loss_(MW)                 52 non-null     object        \n",
      " 5   number_of_customers_affected     91 non-null     object        \n",
      " 6   datetime_of_restoration          123 non-null    object        \n",
      " 7   datetime_of_restoration_cleaned  123 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(6)\n",
      "memory usage: 5.8+ KB\n",
      "These are the columns for sheet 2010 None\n"
     ]
    }
   ],
   "source": [
    "# Look at the info() for each dataframe to confirm our new column \"datetime_of_restoration_cleaned\" contains datetime data:\n",
    "\n",
    "for sheet in list(range(2002, 2011, 1)):\n",
    "    txt = \"These are the columns for sheet {sheet_name}\"\n",
    "    print(txt.format(sheet_name=sheet), DF_dict[\"{0}\".format(sheet)].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning dataframes from the years 2011- 2015:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will move on to the dataframes that contain data for years 2011 - 2014. Lets look at the dataframe:\n",
    "DF_dict[\"2012\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step one, drop values from \"Date Event Began\" that are not datetime datatypes:\n",
    "for sheet in list(range(2011,2015,1)):\n",
    "    drop_non_datetime_values(DF_dict[\"{0}\".format(sheet)], \"Date Event Began\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let us make sure the first column contains the date only. initially some cells had date and time values which resulted in an error when I tried to merge columns later on\n",
    "\n",
    "def date_only(start_year, stop_year, name_of_date_col):\n",
    "    for sheet in list(range(start_year, stop_year+1, 1)):\n",
    "        DF_dict[\"{0}\".format(sheet)][name_of_date_col] = pd.to_datetime(DF_dict[\"{0}\".format(sheet)][name_of_date_col]).dt.date\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let us make sure the first column contains the date only. \n",
    "# Initially some cells had date and time values which resulted in an error when I tried to merge columns later on.\n",
    "\n",
    "date_only(2011,2014,'Date Event Began')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge date and time information\n",
    "\n",
    "for sheet in list(range(2011,2015,1)):\n",
    "    DF_dict[\"{0}\".format(sheet)]['Date Event Began'] = pd.to_datetime(DF_dict[\"{0}\".format(sheet)]['Date Event Began'].astype(str) + ' ' + DF_dict[\"{0}\".format(sheet)][\"Time Event Began\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us make sure the third column contains the date only. initially some cells had date and time values which resulted in an error when I tried to merge columns later on\n",
    "\n",
    "for sheet in list(range(2011,2015,1)):\n",
    "    for ind, row in DF_dict[\"{0}\".format(sheet)].iterrows():\n",
    "        if type(DF_dict[\"{0}\".format(sheet)]['Date of Restoration'][ind]) != datetime:\n",
    "            DF_dict[\"{0}\".format(sheet)]['Date of Restoration'][ind] = datetime.now().date()\n",
    "            #DataFrame_dict[\"sheet{0}\".format(sheet)]['Time of Restoration'][ind] = datetime.now().time()\n",
    "            \n",
    "        if type(DF_dict[\"{0}\".format(sheet)]['Time of Restoration'][ind]) == str:\n",
    "            DF_dict[\"{0}\".format(sheet)]['Time of Restoration'][ind] = \"00:00:00\"\n",
    "    \n",
    "    DF_dict[\"{0}\".format(sheet)]['Date of Restoration'] = pd.to_datetime(DF_dict[\"{0}\".format(sheet)]['Date of Restoration']).dt.date\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sheet in list(range(2011,2015,1)):\n",
    "    DF_dict[\"{0}\".format(sheet)]['Date of Restoration'] = pd.to_datetime(DF_dict[\"{0}\".format(sheet)]['Date of Restoration'].astype(str) + ' ' + DF_dict[\"{0}\".format(sheet)][\"Time of Restoration\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that the \"Date Event Began\" column and \"Date of Restoration\" columns include datetime we can drop the \"Time Event Began\" and \"Time of Restoration\" columns \n",
    "# from the dataframes containing data for years 2011 - 2014\n",
    "\n",
    "for sheet in list(range(2011,2015,1)):\n",
    "    DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].drop([\"Time Event Began\", \"Time of Restoration\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we need to reorder the columns so they are in the same order as the initial sheets we cleaned.\n",
    "\n",
    "for sheet in list(range(2011,2015,1)):\n",
    "    old_col = DF_dict[\"{0}\".format(sheet)].columns.tolist()\n",
    "    DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)][[old_col[0], old_col[3], old_col[2], old_col[4], old_col[5], old_col[6], old_col[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sheet in list(range(2011,2015,1)):\n",
    "    old_col = DF_dict[\"{0}\".format(sheet)].columns.tolist()\n",
    "    for n in range(len(post_cleaning_column_titles)):\n",
    "        DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].rename(columns={old_col[n]: post_cleaning_column_titles[n]})\n",
    "        \n",
    "    if len(old_col) > 7: #Drop all additional columns\n",
    "        for x in range(7,len(old_col),1):\n",
    "            DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].drop(old_col[x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_dict[\"2014\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cleaning dataframes from the years 2016- 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will move on to the dataframes that contain data for years 2015 - 2023. Lets look at the dataframe:\n",
    "DF_dict[\"2018\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop month column because it is redundant and also drop alert criteria column, we will not be analysing this column this time. \n",
    "\n",
    "for sheet in list(range(2015,2024,1)):\n",
    "    column_titles = DF_dict[\"{0}\".format(sheet)].columns.tolist()\n",
    "    if \"Month\" in column_titles:\n",
    "        DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].drop([\"Month\"], axis=1)\n",
    "    if \"Event Month\" in column_titles:\n",
    "        DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].drop([\"Event Month\"], axis=1)\n",
    "    if \"Event Year\" in column_titles:\n",
    "        DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].drop([\"Event Year\"], axis=1)\n",
    "    if \"Alert Criteria\" in column_titles:\n",
    "        DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].drop([\"Alert Criteria\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let us make sure the first column contains the date only. initially some cells had date and time values which resulted in an error when I tried to merge columns later on\n",
    "\n",
    "date_only(2015, 2023, \"Date Event Began\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have data issues in sheets 2015, 2016, 2017. \n",
    "# The issue is that these sheets have many rows of NaNs at the very bottom of the spreadsheet that we need to remove\n",
    "\n",
    "for sheet in list(range(2015,2024,1)):\n",
    "    datetime_col = pd.to_datetime(DF_dict[\"{0}\".format(sheet)]['Date Event Began'], errors='coerce')\n",
    "    print(sheet, datetime_col.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instead of dropping rows that have NaN, how about we keep rows that are not NaN:\n",
    "\n",
    "for sheet in list(range(2015,2024,1)):\n",
    "    DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)][DF_dict[\"{0}\".format(sheet)]['Date Event Began'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code above has resolved the issues of the NaNs at the very bottom of some of the spreadsheets\n",
    "\n",
    "for sheet in list(range(2015,2024,1)):\n",
    "    datetime_col = pd.to_datetime(DF_dict[\"{0}\".format(sheet)]['Date Event Began'], errors='coerce')\n",
    "    print(sheet, datetime_col.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep rows that are not \"Unknown\" \n",
    "# (There are a significant number of unknown values that are preventing us from processing the datetime columns properly)\n",
    "\n",
    "for sheet in list(range(2015,2024,1)):\n",
    "    DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)][DF_dict[\"{0}\".format(sheet)]['Date of Restoration'].str.strip(\" \") !=  \"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge Date Event Began and Time Event Began \n",
    "\n",
    "for sheet in list(range(2015,2024,1)):\n",
    "    DF_dict[\"{0}\".format(sheet)]['Date Event Began'] = pd.to_datetime(DF_dict[\"{0}\".format(sheet)]['Date Event Began'].astype(str) + ' ' + DF_dict[\"{0}\".format(sheet)][\"Time Event Began\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we want to combine the restoration date and restoration time columns. \n",
    "# But first we need to get rid of two problematic rows that are missing critical data\n",
    "\n",
    "DF_dict[\"2022\"].drop(66, axis=0, inplace=True)\n",
    "DF_dict[\"2023\"].drop(13, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sheet in list(range(2015,2024,1)):\n",
    "    DF_dict[\"{0}\".format(sheet)]['Date of Restoration'] = pd.to_datetime(DF_dict[\"{0}\".format(sheet)]['Date of Restoration'].astype(str) + ' ' + DF_dict[\"{0}\".format(sheet)][\"Time of Restoration\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that the \"Date Event Began\" column and \"Date of Restoration\" columns include datetime we can drop the \"Time Event Began\" and \"Time of Restoration\" columns \n",
    "# from the dataframes containing data for years 2011 - 2014\n",
    "\n",
    "for sheet in list(range(2015,2024,1)):\n",
    "    DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].drop([\"Time Event Began\", \"Time of Restoration\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we need to reorder the columns so they are in the same order as the initial sheets we cleaned.\n",
    "\n",
    "for sheet in list(range(2015,2024,1)):\n",
    "    old_col = DF_dict[\"{0}\".format(sheet)].columns.tolist()\n",
    "    DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)][[old_col[0], old_col[3], old_col[2], old_col[4], old_col[5], old_col[6], old_col[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sheet in list(range(2015,2024,1)):\n",
    "    old_col = DF_dict[\"{0}\".format(sheet)].columns.tolist()\n",
    "    for n in range(len(post_cleaning_column_titles)):\n",
    "        DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].rename(columns={old_col[n]: post_cleaning_column_titles[n]})\n",
    "        \n",
    "    if len(old_col) > 7: #Drop all additional columns\n",
    "        for x in range(7,len(old_col),1):\n",
    "            DF_dict[\"{0}\".format(sheet)] = DF_dict[\"{0}\".format(sheet)].drop(old_col[x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF_dict[\"2016\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that dataframes for 2002 - 2023 are fairly clean and standardised, lets concatenate them:\n",
    "\n",
    "disturbances = DF_dict[\"2002\"]\n",
    "\n",
    "for sheet in list(range(2003,2024,1)):\n",
    "    disturbances = disturbances.append(DF_dict[\"{0}\".format(sheet)], ignore_index=True)\n",
    "\n",
    "disturbances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More pre-processing - adjusting the datatypes for easier data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convert the columns \"Datetime_event_began\" and \"Datetime_of_restoration\" to a datetime datatype:\n",
    "\n",
    "disturbances[\"datetime_event_began\"] = pd.to_datetime(disturbances[\"datetime_event_began\"], format= \"%Y-%m-%d %H:%M:%S\", utc=True)\n",
    "#disturbances[\"datetime_of_restoration\"] = pd.to_datetime(disturbances[\"datetime_of_restoration\"], format= \"%Y-%m-%d %H:%M:%S\", utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column \"number_of_customers_affected\" is currently a string, lets try converting this to an int.\n",
    "\n",
    "for ind, row in disturbances.iterrows():\n",
    "    try:\n",
    "        disturbances[\"number_of_customers_affected\"][ind] = int(disturbances[\"number_of_customers_affected\"][ind])\n",
    "    except:\n",
    "        disturbances[\"number_of_customers_affected\"][ind] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets convert the column \"number of customers affected\" to an int\n",
    "\n",
    "disturbances['number_of_customers_affected'] = disturbances['number_of_customers_affected'].fillna(0).astype(int)\n",
    "disturbances['number_of_customers_affected'] = disturbances['number_of_customers_affected'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disturbances['demand_loss_(MW)'].iloc[742] = \"0\"  # Original value = \"datetime(2011, 6, 8, 0, 0)\"\n",
    "\n",
    "# We will also convert the column \"demand_loss_(MW)\" to a float. But first we will replace some values that do not fit the fomat expected:\n",
    "disturbances['demand_loss_(MW)'] = disturbances['demand_loss_(MW)'].replace({\n",
    "    \"500-600\":\"500\",\n",
    "    \"200-250\": \"200\",\n",
    "    \"75-90\":\"75\",\n",
    "    \"75-90 \":\"75\",\n",
    "    \"230-300\":\"230\",\n",
    "    \"500-1000\":\"500\",\n",
    "    \"Approx. 18,500 MW, in MISO area:\":\"18500\",\n",
    "    \"18,500\":\"18500\",\n",
    "    \"4,100 MW (Northern NJ) and 400 MW, (Erie,  PA) area\":\"4500\",\n",
    "    \"peak 1655 \":\"1655\",\n",
    "    \"500-700\":\"500\",\n",
    "    \"Est. 371.1\":\"370\",\n",
    "    \"Est. 75\":\"75\",\n",
    "    \"Approx. 180\":\"180\",\n",
    "    \"Est. 400\":\"400\",\n",
    "    \"Less than 150\":\"150\",\n",
    "    \"Approx. 300\":\"300\",\n",
    "    \"Approx. 30  \":\"30\",\n",
    "    \"Less than 300\":\"300\",\n",
    "    \"Approx. 100\":\"100\",\n",
    "    \"Approx. 85\":\"85\",\n",
    "    \"133 on 5/21/04  between 3:00 a.m. and 4:00  a.m., 392 on 5/21/04 between 4:00 p.m. and 5:00 p.m.\":\"525\",\n",
    "    \"177 on 5/21/04 between 3:00 p.m. and 5:00 p.m.\":\"177\",\n",
    "    \"60 at peak, \":\"60\",\n",
    "    \"-\":\"0\",\n",
    "    \"Approx. 200\":\"200\",\n",
    "    'All':\"0\",\n",
    "    \"65 to 100\":\"65\",\n",
    "    \"50-60 \":\"50\",\n",
    "    \"50-100\":\"50\",\n",
    "    'unknown':\"0\",\n",
    "    '  N/A':\"0\",\n",
    "    \"--\":\"0\",\n",
    "    \"0,\":\"0\",\n",
    "    \"37- 40\":\"37\",\n",
    "    \"100-140\":\"100\",\n",
    "    \"80 to 100\":\"80\",\n",
    "    \"300-500\":\"300\",\n",
    "    \"65-80\":\"65\",\n",
    "    \"8,000-10,000\":\"8000\",\n",
    "    \"800-1,000\":\"800\",\n",
    "    \"8-Jun\":\"0\",\n",
    "    \"900-1000\":\"900\",\n",
    "    \"UNK\":\"0\",\n",
    "    \"Unknown\":\"0\",\n",
    "    \"UNK \":\"0\",\n",
    "})\n",
    "\n",
    "disturbances['demand_loss_(MW)'] = disturbances['demand_loss_(MW)'].fillna(0).astype(int)\n",
    "disturbances['demand_loss_(MW)'] = disturbances['demand_loss_(MW)'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There seem to be some NERC codes that have spaces, lets clean these up by removing the spaces:\n",
    "disturbances[\"NERC_region\"] = disturbances[\"NERC_region\"].str.replace(\" \", \"\")\n",
    "\n",
    "# We also want to address some naming inconsistencies in the data:\n",
    "disturbances[\"NERC_region\"] = disturbances[\"NERC_region\"].replace(\n",
    "    {\n",
    "        \"RF\":\"RFC\",\n",
    "        \"RF/SERC\":\"SERC/RF\",\n",
    "        \"MRO/SERC\":\"SERC/MRO\",\n",
    "        \"RFC;SERC\":\"SERC/RFC\",\n",
    "        \"NPPC\":\"NPCC\",\n",
    "        \"RF/MRO\":\"MRO/RF\",\n",
    "        \"MR0\":\"MRO\",\n",
    "        \"NPCC,RFC\":\"NPCC/RFC\",\n",
    "        \"NPCC;RFC\":\"NPCC/RFC\",\n",
    "        \"RFC,SERC\":\"SERC/RFC\",\n",
    "        \"SPP,SERC,TRE\":\"SERC/SPP/TRE\",\n",
    "        \"NP\":\"NPCC\",\n",
    "        \"MECO\":\"Other\",\n",
    "        \"REC\":\"Other\",\n",
    "        \"HI\":\"Other\",\n",
    "        \"MidwestISO(RFC\":\"Other\",\n",
    "        \"TE\":\"Other\",\n",
    "        \"WeEnergiesMAIN\":\"Other\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disturbances.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The features we want to work with (\"datetime_event_began\", \"demand_loss_(MW)\", and \"number_of_customers_affected\") are now in the correct format. EDA can begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the timezome for the column \"datetime_event_began\" so that we can write to excel:\n",
    "#disturbances['datetime_event_began'] = disturbances['datetime_event_began'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disturbances.to_csv('disturbances2002_2023_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data exploration will focus on two features from the dataset: NERC Region and Demand Loss (MW). The North American Electric Reliability Corportion (NERC) is concerned about regional weknesses in the energy grid and want to know where to focus their energy if they want to improve energy reliability across their regional portfolio. This analysis is the first step toward understanding where the most powere outage events are happening as well as how much demand loss occers per event. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What North American Electric Reliability Corportion (NERC) regions had the most outages from 2002-2023?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe that defines the NERC Region codes. We will use this as a legend for the figure below.\n",
    "\n",
    "NERC_region_dict = {\"NERC region codes\":\n",
    "    {\"MRO\": \"Midwest Reliability Organisation\",\n",
    "    \"NPCC\": \"Northeast Power Coordinating Council\",\n",
    "    \"RFC\": \"ReliabilityFirst Corporation\",\n",
    "    \"SERC\": \"SERC Reliability Corporation\",\n",
    "    \"SPP\": \"Southwest Power Pool\",\n",
    "    \"TRE\": \"Texas Reliability Entity\",\n",
    "    \"WECC\": \"Western Electricity Coordinating Council\",\n",
    "    \"FRCC\": \"Florida Reliability Coordinating Council\",\n",
    "    \"MAPP\": \"Mid-continent Area Power Pool\",\n",
    "    \"HECO\": \"Hawaiian Electric\",\n",
    "    \"MAAC\": \"Mid-Atlantic Area Council\",\n",
    "    \"WSCC\": \"Western Systems Coordinating Council\",\n",
    "    \"MAIN\": \"Mid-America Interconnected Network\",\n",
    "    \"ERCOT\": \"Electric Reliability Council of Texas\",\n",
    "    \"ECAR\": \"East Central Area Reliability Coordination Agreement\",\n",
    "    \"SPP RE\": \"SPP Regional Entity\"}\n",
    "}\n",
    "\n",
    "NERC_region_df = pd.DataFrame(NERC_region_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sns.countplot(data=disturbances, y='NERC_region', order=disturbances['NERC_region'].value_counts().index, dodge=False)\n",
    "plt.title(\"NERC Regions with power outage disturbances 2022 - 2023\")\n",
    "\n",
    "# Add a table to the right of the plot:\n",
    "Legend_table = plt.table(cellText= NERC_region_df.values,\n",
    "                        rowLabels= NERC_region_df.index,\n",
    "                        colLabels= NERC_region_df.columns,\n",
    "                        bbox=(1.1, .2, 0.5, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above, we can see that the majority of outage events occur in 6-7 NERC regions. It is unclear at this stage whether this has anything to do with sampling bias. More analysis is necessary. My recommendation for NERC is to investigate the following regions more closely to see if there are grid weaknesses that need addressing. These regions had the most outage events from 2002 - 2023:\n",
    "- Western Electricity Coordinating Council\n",
    "- Reliability First Corporation\n",
    "- SERC Reliability Corporation\n",
    "- Northeast Power Coordinating Council\n",
    "- Texas Reliability Entity\n",
    "- Midwest Reliability Reliability Organisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much demand loss (in MW) can be expected in a typical outage event? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at the regions of interested above and see what the demand loss looks like per region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))  #NOTE: Figsize needs to be executed before the boxplot method of else it will not apply\n",
    "sns.boxplot(\n",
    "    data=disturbances[disturbances['NERC_region'].isin([\"WECC\", \"RFC\", \"SERC\", \"NPCC\", \"TRE\", \"MRO\"])],\n",
    "    x='NERC_region',\n",
    "    y='demand_loss_(MW)'\n",
    ")\n",
    "\n",
    "plt.title(\"Power outage demand loss per NERC Region\")\n",
    "plt.xlabel(\"NERC region\")\n",
    "plt.ylabel(\"Demand loss (MW)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data above if difficult to understand due to the outliers in the data. lets cap upper and lower bounds so that we can interpret our box plots better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finding IQR:\n",
    "q3 = disturbances[\"demand_loss_(MW)\"].quantile(0.75)\n",
    "q1 = disturbances[\"demand_loss_(MW)\"].quantile(0.25)\n",
    "iqr = q3 - q1 \n",
    "\n",
    "# Get observations that are greater than 1.5 * iqr:\n",
    "upper_bound = q3 + (1.5 * iqr)\n",
    "lower_bound = q1 - (1.5 * iqr)\n",
    "\n",
    "disturbances[\"demand_loss_(MW)_clipped\"] = np.clip(disturbances[\"demand_loss_(MW)\"], lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))  #NOTE: Figsize needs to be executed before the boxplot method of else it will not apply\n",
    "sns.boxplot(\n",
    "    data=disturbances[disturbances['NERC_region'].isin([\"WECC\", \"RFC\", \"SERC\", \"NPCC\", \"TRE\", \"MRO\"])],\n",
    "    x='NERC_region',\n",
    "    y='demand_loss_(MW)_clipped' #Use the clipped data to get rid of outliers\n",
    ")\n",
    "\n",
    "plt.title(\"Power outage demand loss per NERC Region\")\n",
    "plt.xlabel(\"NERC region\")\n",
    "plt.ylabel(\"Demand loss (MW)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets have a closer look at the 6 regions with the most logged disturbances. \n",
    "\n",
    "disturbances[disturbances['NERC_region'].isin([\"WECC\", \"RFC\", \"SERC\", \"NPCC\", \"TRE\", \"MRO\"])].groupby([\"NERC_region\"]).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, the median demand loss for these regions is zero. This does not seem right and means we need to have a closer look at the data. \n",
    "- Is demand loss being logged properly? \n",
    "- Do we have any negative values that could be skewing the data? \n",
    "\n",
    "More analysis needs to take place so that we can answer these questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there any major outliers in terms of demand loss? What are the features of these outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "sns.lineplot(data=disturbances, x='datetime_event_began', y=\"demand_loss_(MW)\")\n",
    "\n",
    "plt.title(\"Demand loss (MW) for outages between 2002 - 2023\")\n",
    "plt.xlabel(\"Date of outage\")\n",
    "plt.ylabel(\"Demand loss (MW)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_loss_sorted = disturbances['demand_loss_(MW)'].sort_values(ascending=False)\n",
    "demand_loss_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By sorting the data by demand loss we could get a rough idea about how we want to slice the data to view the events \n",
    "# that are responsible for the most demand loss.\n",
    "\n",
    "disturbances[disturbances[\"demand_loss_(MW)\"] > 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Severe weather seems to be the leading cause of the most disruptive power outages. over 50% of the top 14 outage events (ranked by demand loss) are caused by severe weather. More analysis will need to take place to understand what types of sever weather are most impactful to the energy grid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Conclusion and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I spent a lot of time cleaning this data and the EDA I was able to complete by November 27th is a bit limited. I had a lot of fun working with this messy dataset but also have a lot of questions. I know there is a lot to improve. \n",
    "\n",
    "Some general notes:\n",
    "- I wanted to explote the datetime columns more but the data was so messy and I was very stuck on timezones... I abandoned this so that I could at least submit something on time!\n",
    "\n",
    "\n",
    "Other notes:\n",
    "- NOTE: I have lost some of the merged cell data from the area column of 2002 sheet, to revisit and look at data dictionary for better understanding\n",
    "- NOTE: Have i deleted some important data when cleaning my rows that are not datetime data? to review.\n",
    "- NOTE: when converting the datetime columns to datetime datatypes I set utc=True. This will need to be reviewed.\n",
    "- NOTE: This is where I found the NERC region code translations: https://www.eia.gov/outlooks/aeo/pdf/nerc_map.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
